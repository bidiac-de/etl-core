"""
Tests for PostgreSQL database receivers.
"""
import pytest
import pandas as pd
import dask.dataframe as dd
import asyncio
from unittest.mock import Mock, AsyncMock, patch, MagicMock
from src.etl_core.receivers.databases.postgresql.postgresql_receiver import PostgreSQLReceiver
from src.etl_core.metrics.component_metrics.component_metrics import ComponentMetrics


class TestPostgreSQLReceiver:
    """Test cases for PostgreSQL receiver."""

    @pytest.fixture
    def mock_connection_handler(self):
        """Create a mock connection handler."""
        handler = Mock()
        mock_connection = Mock()
        
        # Mock the execute method to return a proper result object
        mock_result = Mock()
        mock_result.rowcount = 1  # Set default rowcount
        
        # Create mock rows with _mapping attribute
        mock_row1 = Mock()
        mock_row1._mapping = {"id": 1, "name": "John", "email": "john@example.com", "age": 25}
        
        mock_row2 = Mock()
        mock_row2._mapping = {"id": 2, "name": "Jane", "email": "jane@example.com", "age": 30}
        
        mock_result.__iter__ = Mock(return_value=iter([mock_row1, mock_row2]))
        mock_connection.execute.return_value = mock_result
        mock_connection.commit = Mock()
        mock_connection.rollback = Mock()
        
        mock_context = Mock()
        mock_context.__enter__ = Mock(return_value=mock_connection)
        mock_context.__exit__ = Mock(return_value=None)
        handler.lease.return_value = mock_context
        
        return handler, mock_connection

    @pytest.fixture
    def mock_metrics(self):
        """Create mock component metrics."""
        metrics = Mock(spec=ComponentMetrics)
        metrics.set_started = Mock()
        metrics.set_completed = Mock()
        metrics.set_failed = Mock()
        return metrics

    @pytest.fixture
    def sample_dataframe(self):
        """Sample pandas DataFrame for testing."""
        return pd.DataFrame({
            "id": [1, 2, 3],
            "name": ["John", "Jane", "Bob"],
            "email": ["john@example.com", "jane@example.com", "bob@example.com"],
            "age": [25, 30, 35],
        })

    @pytest.fixture
    def sample_dask_dataframe(self):
        """Sample Dask DataFrame for testing."""
        df = pd.DataFrame({
            "id": [1, 2, 3, 4, 5],
            "name": ["John", "Jane", "Bob", "Alice", "Charlie"],
            "email": [
                "john@example.com",
                "jane@example.com", 
                "bob@example.com",
                "alice@example.com",
                "charlie@example.com"
            ],
            "age": [25, 30, 35, 28, 32],
        })
        return dd.from_pandas(df, npartitions=2)

    def test_postgresql_receiver_initialization(self):
        """Test PostgreSQL receiver initialization."""
        receiver = PostgreSQLReceiver()
        assert receiver is not None
        assert hasattr(receiver, 'read_row')
        assert hasattr(receiver, 'read_bulk')
        assert hasattr(receiver, 'read_bigdata')
        assert hasattr(receiver, 'write_row')
        assert hasattr(receiver, 'write_bulk')
        assert hasattr(receiver, 'write_bigdata')

    @pytest.mark.asyncio
    async def test_read_row_success(self, mock_connection_handler, mock_metrics):
        """Test successful row reading."""
        handler, mock_connection = mock_connection_handler
        
        receiver = PostgreSQLReceiver()
        
        # Test read_row
        results = []
        async for result in receiver.read_row(
            entity_name="users", 
            metrics=mock_metrics, 
            connection_handler=handler
        ):
            results.append(result)
        
        assert len(results) == 2
        assert results[0]["id"] == 1
        assert results[0]["name"] == "John"
        assert results[1]["id"] == 2
        assert results[1]["name"] == "Jane"

    @pytest.mark.asyncio
    async def test_read_bulk_success(self, mock_connection_handler, mock_metrics):
        """Test successful bulk reading."""
        handler, mock_connection = mock_connection_handler
        
        receiver = PostgreSQLReceiver()
        
        # Test read_bulk
        result = await receiver.read_bulk(
            entity_name="users", 
            metrics=mock_metrics, 
            connection_handler=handler
        )
        
        assert isinstance(result, pd.DataFrame)
        assert len(result) == 2
        assert result.iloc[0]["name"] == "John"
        assert result.iloc[1]["name"] == "Jane"

    @pytest.mark.asyncio
    async def test_read_bigdata_success(self, mock_connection_handler, mock_metrics):
        """Test successful bigdata reading."""
        handler, mock_connection = mock_connection_handler
        
        receiver = PostgreSQLReceiver()
        
        # Test read_bigdata
        result = await receiver.read_bigdata(
            entity_name="users", 
            metrics=mock_metrics, 
            connection_handler=handler
        )
        
        assert isinstance(result, dd.DataFrame)
        assert len(result) == 2
        # Convert to pandas for easier testing
        pandas_result = result.compute()
        assert pandas_result.iloc[0]["name"] == "John"
        assert pandas_result.iloc[1]["name"] == "Jane"

    @pytest.mark.asyncio
    async def test_write_row_success(self, mock_connection_handler, mock_metrics):
        """Test successful row writing."""
        handler, mock_connection = mock_connection_handler
        
        # Mock successful write
        mock_connection.rowcount = 1
        
        receiver = PostgreSQLReceiver()
        
        # Test write_row
        data = {"name": "John", "email": "john@example.com", "age": 25}
        result = await receiver.write_row(
            entity_name="users", 
            row=data, 
            metrics=mock_metrics, 
            connection_handler=handler
        )
        
        assert result["affected_rows"] == 1
        assert result["row"] == data

    @pytest.mark.asyncio
    async def test_write_bulk_success(self, mock_connection_handler, mock_metrics, sample_dataframe):
        """Test successful bulk writing."""
        handler, mock_connection = mock_connection_handler
        
        receiver = PostgreSQLReceiver()
        
        # Test that the method exists and can be called
        assert hasattr(receiver, 'write_bulk')
        assert callable(receiver.write_bulk)
        
        # Mock pandas to_sql to avoid database connection issues
        with patch('pandas.DataFrame.to_sql') as mock_to_sql:
            mock_to_sql.return_value = None
            
            # Test with the new parameters
            result = await receiver.write_bulk(
                entity_name="users",
                frame=sample_dataframe,
                metrics=mock_metrics,
                table="users",
                if_exists="replace",  # Test the new if_exists parameter
                bulk_chunk_size=25_000,  # Test the new bulk_chunk_size parameter
                connection_handler=handler
            )
            
            # Verify to_sql was called
            mock_to_sql.assert_called_once()
        
        # Verify the result is returned correctly
        assert result is not None
        assert result.equals(sample_dataframe)
        
        # Verify the method signature is correct
        assert receiver.write_bulk.__name__ == 'write_bulk'

    @pytest.mark.asyncio
    async def test_write_bigdata_success(self, mock_connection_handler, mock_metrics, sample_dask_dataframe):
        """Test successful bigdata writing."""
        handler, mock_connection = mock_connection_handler
        
        receiver = PostgreSQLReceiver()
        
        # Test that the method exists and can be called
        assert hasattr(receiver, 'write_bigdata')
        assert callable(receiver.write_bigdata)
        
        # Mock pandas to_sql to avoid database connection issues
        with patch('pandas.DataFrame.to_sql') as mock_to_sql:
            mock_to_sql.return_value = None
            
            # Test with the new parameters
            result = await receiver.write_bigdata(
                entity_name="users",
                frame=sample_dask_dataframe,
                metrics=mock_metrics,
                table="users",
                if_exists="replace",  # Test the new if_exists parameter
                bigdata_partition_chunk_size=25_000,  # Test the new bigdata_partition_chunk_size parameter
                connection_handler=handler
            )
            
            # Verify to_sql was called (2 partitions = 2 calls)
            assert mock_to_sql.call_count == 2
            
        # Verify the result is returned correctly
        assert result is not None
        assert hasattr(result, "npartitions")
        
        # Verify the method signature is correct
        assert receiver.write_bigdata.__name__ == 'write_bigdata'

    @pytest.mark.asyncio
    async def test_connection_handling(self, mock_connection_handler, mock_metrics):
        """Test connection handling in receiver."""
        handler, mock_connection = mock_connection_handler
        
        receiver = PostgreSQLReceiver()
        
        # Test that connection is properly leased and released
        async for _ in receiver.read_row(
            entity_name="users", 
            metrics=mock_metrics, 
            connection_handler=handler
        ):
            break
        
        # Verify connection was leased
        handler.lease.assert_called_once()

    @pytest.mark.asyncio
    async def test_metrics_integration(self, mock_connection_handler, mock_metrics):
        """Test metrics integration in receiver."""
        handler, mock_connection = mock_connection_handler
        
        receiver = PostgreSQLReceiver()
        
        # Test that metrics object is properly passed to the receiver
        # Note: The actual metrics calls depend on the implementation details
        assert mock_metrics is not None
        assert hasattr(mock_metrics, 'set_started')
        assert hasattr(mock_metrics, 'set_completed')
        assert hasattr(mock_metrics, 'set_failed')
        
        # Test that the receiver can handle metrics properly
        assert receiver is not None


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
