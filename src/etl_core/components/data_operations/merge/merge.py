from __future__ import annotations

from typing import Any, AsyncIterator, Dict, List, Tuple, Union

import dask.dataframe as dd
import pandas as pd
from pydantic import Field, PrivateAttr, model_validator, ConfigDict

from etl_core.components.component_registry import register_component
from etl_core.components.data_operations.data_operations import DataOperationsComponent
from etl_core.receivers.data_operations_receivers.merge.merge_receiver import MergeReceiver
from etl_core.job_execution.job_execution_handler import InTagged, Out
from etl_core.metrics.component_metrics.data_operations_metrics.data_operations_metrics import (
    DataOperationsMetrics,
)
from etl_core.components.wiring.ports import InPortSpec, OutPortSpec


@register_component("merge")
class MergeComponent(DataOperationsComponent):
    """
    Merge component: routes payloads from multiple named input ports to a single output port.
    The component does not combine/aggregate â€” it simply forwards each incoming payload
    to the configured single output. Useful to unite multiple sources into a single downstream path.
    Config:
      - inputs: list[str]  (names of input ports)
      - output: str        (name of single output port)
    """

    model_config = ConfigDict(arbitrary_types_allowed=True, extra="ignore")

    INPUT_PORTS: Tuple[InPortSpec, ...] = (InPortSpec(name="in", required=True, fanin="many"),)
    OUTPUT_PORTS: Tuple[OutPortSpec, ...] = (OutPortSpec(name="merge", required=True, fanout="one"),)

    @model_validator(mode="after")
    def _build_objects(self):
        self._receiver = MergeReceiver()
        return self

    async def process_row(
        self,
        row: Dict[str, Any],
        metrics: DataOperationsMetrics,
    ) -> AsyncIterator[Out]:
        """Forward a single row (or tagged envelope) to the single output port."""
        async for port_spec, payload_out in self._receiver.process_row(out_port=self.OUTPUT_PORTS[0], row=row, metrics=metrics):
            yield Out(port=port_spec.name, payload=payload_out)

    async def process_bulk(
        self,
        dataframe: Union[pd.DataFrame, InTagged],
        metrics: DataOperationsMetrics,
    ) -> AsyncIterator[Out]:
        """Forward a DataFrame (or tagged envelope) to the single output port."""

        async for port_spec, payload_out in self._receiver.process_bulk(out_port=self.OUTPUT_PORTS[0], dataframe=dataframe, metrics=metrics):
            yield Out(port=port_spec.name, payload=payload_out)

    async def process_bigdata(
        self,
        ddf: Union[dd.DataFrame, InTagged],
        metrics: DataOperationsMetrics,
    ) -> AsyncIterator[Out]:
        """Forward a Dask DataFrame (or tagged envelope) to the single output port."""

        async for port_spec, payload_out in self._receiver.process_bigdata(out_port=self.OUTPUT_PORTS[0], ddf=ddf, metrics=metrics):
            yield Out(port=port_spec.name, payload=payload_out)